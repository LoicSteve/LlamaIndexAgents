{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components in LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installinmg dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip wheel setuptools -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index datasets llama-index-callbacks-arize-phoenix llama-index-vector-stores-chroma llama-index-llms-huggingface-api -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02dd030bbdf4ab6b78bd9d280ae5702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Query engine for RAG\n",
    "\n",
    "#### Setting up the persona database \n",
    "i will be using personas from the https://huggingface.co/datasets/dvilasuero/finepersonas-v0.1-tiny. This dataset contains 5K personas that will be attending the party!\n",
    "\n",
    "Let's load the dataset and store it as files in the data directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loicsteve/Desktop/LlamaIndexAgents/LlamaIndexAgent/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "dataset = load_dataset(path=\"dvilasuero/finepersonas-v0.1-tiny\", split=\"train\")\n",
    "\n",
    "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "for i, persona in enumerate(dataset):\n",
    "    with open(Path(\"data\") / f\"persona_{i}.txt\", \"w\") as f:\n",
    "        f.write(persona[\"persona\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have a local directory with all the personas that will be attending the party, we can load and index!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and embedding persona documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the SimpleDirectoryReader to load the persona descriptions from the data directory. This will return a list of Document objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(input_dir=\"data\")\n",
    "documents = reader.load_data()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of Document objects, we can use the IngestionPipeline to create nodes from the documents and prepare them for the QueryEngine. We will use the SentenceSplitter to split the documents into smaller chunks and the HuggingFaceInferenceAPIEmbedding to embed the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "# create the pipeline with transformations\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_overlap=0),\n",
    "        HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "nodes = await pipeline.arun(documents=[Document.example()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextNode(id_='0a4fbdcb-51bc-4a15-9fc4-2aff565f72ca', embedding=[-0.0777985155582428, -0.029093926772475243, 0.0022167284041643143, -0.010391009971499443, 0.0900288000702858, -0.06914414465427399, 0.00825283583253622, -0.009724952280521393, 0.019781211391091347, -0.043472062796354294, 0.02659621275961399, -0.009204167872667313, 0.0787544846534729, 0.0025490913540124893, 0.04259764030575752, 0.03183037042617798, 0.003503598039969802, 0.02002204954624176, -0.020237090066075325, -0.00946001335978508, 0.04732130095362663, 0.015019409358501434, -2.0768840840901248e-05, 0.005134056322276592, 0.012225973419845104, 0.0963548868894577, -0.03063950501382351, -0.03588945046067238, -0.021210353821516037, -0.1618298888206482, 0.03443855047225952, -0.022891050204634666, 0.06059262901544571, 0.03163774311542511, -0.02275249920785427, 0.004881291184574366, -0.011713894084095955, 0.0013522659428417683, -0.032165948301553726, 0.047184307128190994, 0.006247331388294697, 0.011993998661637306, -0.025094186887145042, 0.06388942152261734, -0.04053845256567001, -0.06997141987085342, -0.023824546486139297, 0.0034193217288702726, -0.07516695559024811, -0.006700171623378992, -0.04823628440499306, -0.021553387865424156, 0.015732241794466972, 0.03213910013437271, 0.04297225922346115, 0.03052620217204094, 0.016532577574253082, 0.01185401901602745, -0.012009771540760994, 0.03567727655172348, 0.06410665065050125, 0.023510029539465904, -0.08524465560913086, 0.09171333909034729, -0.0239399466663599, 0.05063389614224434, -0.004476979840546846, -0.041152212768793106, 0.007853042334318161, 0.016853537410497665, 0.007407373283058405, -0.03402787446975708, -0.017441676929593086, 0.057371363043785095, 0.0489729568362236, 0.041949160397052765, -0.0030741326045244932, -0.003927180077880621, 0.03926164284348488, 0.05760858952999115, -0.08952855318784714, -0.061358172446489334, 0.015300055965781212, -0.05624854564666748, 0.012189902365207672, 0.0011663581244647503, -0.024655980989336967, -0.015216218307614326, 0.020693833008408546, -0.041584812104701996, -0.021999826654791832, -0.033254895359277725, -0.01850888505578041, 0.0199640691280365, -0.006760851480066776, -0.024649322032928467, -0.014548146165907383, 0.021871007978916168, -0.020344417542219162, 0.3600023090839386, -0.04310816526412964, -0.003665466560050845, -0.054372482001781464, 0.02342919073998928, -0.021912220865488052, -0.043047696352005005, -0.0009716714848764241, 0.0039198449812829494, 0.020078416913747787, -0.011307211592793465, 0.0008229182567447424, -0.027253668755292892, -0.017859896644949913, 0.02203017845749855, -0.01977171190083027, 0.001256320159882307, -0.0017979656113311648, 0.00042718881741166115, 0.013368488289415836, 0.048375919461250305, -0.04627829045057297, 0.012445359490811825, -0.0012309275334700942, 0.010645492933690548, 0.045347560197114944, 0.011425015516579151, -0.009212993085384369, 0.03376760706305504, 0.011776897124946117, 0.007324594538658857, 0.06729656457901001, 0.023339491337537766, -0.13160251080989838, -0.03453606367111206, 0.07752537727355957, -0.015987960621714592, 0.036899227648973465, -0.06302450597286224, 0.03002934530377388, -0.021570667624473572, -0.040226198732852936, 0.0025860604364424944, 0.00982684176415205, 0.012523452751338482, -0.03627578914165497, 0.11236551403999329, -0.014924738556146622, -0.016017045825719833, -0.09487797319889069, -0.037087175995111465, 0.004804791882634163, 0.037222255021333694, -0.04047798365354538, -0.021092792972922325, 0.03566205874085426, 0.02643664926290512, 0.0635301023721695, -0.030120141804218292, -0.025635844096541405, 0.04007701203227043, -0.050258081406354904, 0.0038370827678591013, -0.017709428444504738, 0.1086927130818367, -0.03558376058936119, -0.1391076296567917, -0.01245791930705309, 0.036700937896966934, -0.0056605092249810696, -0.06887217611074448, 0.0034669176675379276, 0.06423718482255936, -0.06642124056816101, 0.026294097304344177, -0.029476115480065346, 0.012291772291064262, -0.05581209063529968, -0.027627339586615562, -0.016671855002641678, 0.014924855902791023, 0.019634701311588287, -0.04031023383140564, -0.03139470890164375, -0.023121612146496773, -0.05386532470583916, 0.012522030621767044, -0.017023948952555656, -0.0426926463842392, 0.02316056191921234, -0.07771175354719162, 0.029437623918056488, 0.058561280369758606, 0.014747817069292068, 0.03805220499634743, 0.01806580275297165, -0.03727971762418747, -0.05041397362947464, 0.030869653448462486, 0.02125515230000019, -0.025860443711280823, 0.047392722219228745, 0.05093775689601898, 0.026461170986294746, 0.09818754345178604, -0.02224007062613964, 0.022124599665403366, -0.03831537812948227, -0.04925483092665672, 0.04202914983034134, -0.015139449387788773, -0.028199847787618637, -0.011002824641764164, -0.014427658170461655, -0.029844658449292183, -0.004015898797661066, 0.02496257610619068, 0.09937809407711029, 0.01827012002468109, -0.027451014146208763, -0.030975783243775368, -0.0385558046400547, -0.018061621114611626, 0.0010970472358167171, -0.33157676458358765, 0.00043076457222923636, -0.020481370389461517, 0.007462431211024523, -0.06342694908380508, -0.06453309953212738, -0.005442955065518618, 0.03136394917964935, -0.026107827201485634, 0.05385288968682289, 0.06509579718112946, -0.018577661365270615, -0.021019209176301956, -0.03142851963639259, -0.01043759472668171, -0.027210185304284096, 0.006158892530947924, 0.007246627006679773, -0.027127884328365326, 0.06292755901813507, -0.018640950322151184, 0.014546818099915981, -0.007638042792677879, -0.07458765059709549, 0.018129752948880196, -0.000305128691252321, 0.12270020693540573, 0.0034088720567524433, -0.003883928060531616, -0.025630567222833633, 0.0035563199780881405, 0.0036340609658509493, -0.013149331323802471, -0.09405974298715591, -0.003675158368423581, -0.0762249305844307, -0.015537474304437637, 0.0015020145801827312, 0.028042465448379517, 0.016827009618282318, -0.06330444663763046, 0.0012277582427486777, 0.0032455590553581715, -0.06673432141542435, -0.024519143626093864, 0.011157700791954994, 0.009110099636018276, -0.07436948269605637, -0.0010464562801644206, 0.027751732617616653, -0.017853036522865295, 0.017683926969766617, 0.02795828878879547, 0.036274321377277374, -0.08799850195646286, 0.008186537772417068, -0.07093992829322815, -0.017039982602000237, -0.03830127790570259, -0.04413563013076782, -0.004396457690745592, 0.010843787342309952, 0.017635323107242584, -0.058812208473682404, -0.010367645882070065, -0.02149307355284691, 0.026498300954699516, 0.016036616638302803, 0.04696490243077278, -0.051005374640226364, -0.0531432218849659, 0.06379017233848572, -0.028786949813365936, 0.02287083864212036, 0.002018252620473504, 0.09648659080266953, 0.026217583566904068, 0.011250830255448818, -0.0069746943190693855, 0.009370162151753902, 0.03975263237953186, 0.06405079364776611, 0.014033980667591095, 0.05119076743721962, 0.015860173851251602, 0.027214739471673965, -0.0035292571410536766, 0.025411490350961685, 0.025589529424905777, 0.006962361745536327, 0.018449077382683754, -0.019458040595054626, -0.0408986359834671, -0.03710374981164932, -0.013878146186470985, 0.022831635549664497, -0.21189971268177032, 0.011655536480247974, -0.009478962980210781, 0.04524368792772293, -0.03718551993370056, 0.012075033970177174, 0.03230690211057663, -0.05436020717024803, 0.0801200121641159, 0.010396158322691917, -0.006840575952082872, 0.0236473698168993, 0.019083280116319656, -0.08675038069486618, 0.0556868351995945, -0.04244045913219452, 0.07937945425510406, 0.04756636917591095, -0.0012175095034763217, 0.022605938836932182, 0.04070865735411644, -0.014757254160940647, 0.21329565346240997, 0.04872790724039078, -0.09012961387634277, 0.0645013377070427, -0.005620740819722414, 0.022148555144667625, 0.07590370625257492, 0.09106605499982834, 0.01802970841526985, 0.04839025065302849, 0.13862378895282745, 0.010350991040468216, 0.0029714342672377825, -0.011156583204865456, 0.0036706740502268076, 0.049469541758298874, 0.052449628710746765, 0.018158454447984695, 0.008198692463338375, 0.01754811219871044, -0.0064780013635754585, 0.05942355841398239, 0.052878912538290024, 0.026182541623711586, -0.011093328706920147, -0.12569931149482727, -0.020619546994566917, 0.04062195494771004, -0.06438937038183212, -0.055390506982803345, -0.02713465690612793, 0.0110793961212039, -0.010758369229733944, -0.029231345281004906, 0.022257398813962936, 0.00047493635793216527, 0.052039243280887604, -0.005292757414281368, -0.015183713287115097, -0.02127612754702568, 0.06365647912025452, -0.0009494341793470085, 0.02266782522201538], metadata={'filename': 'README.md', 'category': 'codebase'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8a77fdc5-b47b-4f89-9326-071445bd2e7f', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'filename': 'README.md', 'category': 'codebase'}, hash='8f24ce02310203160c5e18490ef2c8acba3077d47170f8d9ae1191e323687c3a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Context\\nLLMs are a phenomenal piece of technology for knowledge generation and reasoning.\\nThey are pre-trained on large amounts of publicly available data.\\nHow do we best augment LLMs with our own private data?\\nWe need a comprehensive toolkit to help perform this data augmentation for LLMs.\\n\\nProposed Solution\\nThat\\'s where LlamaIndex comes in. LlamaIndex is a \"data framework\" to help\\nyou build LLM  apps. It provides the following tools:\\n\\nOffers data connectors to ingest your existing data sources and data formats\\n(APIs, PDFs, docs, SQL, etc.)\\nProvides ways to structure your data (indices, graphs) so that this data can be\\neasily used with LLMs.\\nProvides an advanced retrieval/query interface over your data:\\nFeed in any LLM input prompt, get back retrieved context and knowledge-augmented output.\\nAllows easy integrations with your outer application framework\\n(e.g. with LangChain, Flask, Docker, ChatGPT, anything else).\\nLlamaIndex provides tools for both beginner users and advanced users.\\nOur high-level API allows beginner users to use LlamaIndex to ingest and\\nquery their data in 5 lines of code. Our lower-level APIs allow advanced users to\\ncustomize and extend any module (data connectors, indices, retrievers, query engines,\\nreranking modules), to fit their needs.', mimetype='text/plain', start_char_idx=1, end_char_idx=1279, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing and indexing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata length (21) is close to chunk size (25). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (21) is close to chunk size (25). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (21) is close to chunk size (25). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (21) is close to chunk size (25). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (22) is close to chunk size (25). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (22) is close to chunk size (25). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (22) is close to chunk size (25). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (22) is close to chunk size (25). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (22) is close to chunk size (25). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (22) is close to chunk size (25). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"alfred\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=25, chunk_overlap=0),\n",
    "        HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "nodes = await pipeline.arun(documents=documents[:10])\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create this index from our vector store and embeddings\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying a VectorStoreIndex with prompts and LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='The meaning of life is not addressed in the provided information.', source_nodes=[NodeWithScore(node=TextNode(id_='68f3d4b5-3430-4783-b30a-806eb9acf02c', embedding=None, metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='24e36899-ca32-4944-b60f-175d9b9aba26', node_type='4', metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, hash='e8f6a6656fcf54071fa082a0f84538f1f4291fa6a33e47565d1f246cefeb42e6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='3b74273f-46d5-4260-9257-8d956b41f05b', node_type='1', metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, hash='116f109d4adf6ba77f4361fde44af68e8e517c9ae82dd35f7b783df7c7bee265')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='of life.', mimetype='text/plain', start_char_idx=258, end_char_idx=266, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4314102701318791), NodeWithScore(node=TextNode(id_='aba83c3e-bd0a-4948-8983-bebffede054f', embedding=None, metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1000.txt', 'file_name': 'persona_1000.txt', 'file_type': 'text/plain', 'file_size': 133, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3bb3fb9a-d8a9-4a9c-9a66-507f82a1209f', node_type='4', metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1000.txt', 'file_name': 'persona_1000.txt', 'file_type': 'text/plain', 'file_size': 133, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, hash='e321d33ed36f0aa8301c9e0f3d75f9c8e517bed6f1541ea78caacbe651b25af6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5c1b4314-dd1c-480f-8cf5-01373ca2a673', node_type='1', metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1000.txt', 'file_name': 'persona_1000.txt', 'file_type': 'text/plain', 'file_size': 133, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, hash='9f88412e410dc17354313b33153a74939ea172751c043f7f553065804b61cc82'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2d61550a-c2ed-43d1-af66-e380a56ff888', node_type='1', metadata={}, hash='aa6f54e69fb9cf16268ae3b2e49dfcd73a43fb9043fe99add6916656477d6897')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='respiratory system and', mimetype='text/plain', start_char_idx=97, end_char_idx=119, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.3569178643070755)], metadata={'68f3d4b5-3430-4783-b30a-806eb9acf02c': {'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, 'aba83c3e-bd0a-4948-8983-bebffede054f': {'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1000.txt', 'file_name': 'persona_1000.txt', 'file_type': 'text/plain', 'file_size': 133, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "\n",
    "llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    response_mode=\"tree_summarize\",\n",
    ")\n",
    "query_engine.query(\"What is the meaning of life?\")\n",
    "# The meaning of life is 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=\"Certainly! Here's a response using the persona described:\\n\\nAs a cultural expert and anthropologist, I have had the privilege of exploring diverse cultures around the world. My travels have taken me from the bustling markets of Marrakech to the serene landscapes of the Andes, where I've lived among indigenous communities, learning about their traditions and ways of life. Each journey has enriched my understanding of human diversity and the intricate tapestry of global cultures.\", source_nodes=[NodeWithScore(node=TextNode(id_='10749000-c49f-4368-a98c-9e2dfc0d6de3', embedding=None, metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='24e36899-ca32-4944-b60f-175d9b9aba26', node_type='4', metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, hash='e8f6a6656fcf54071fa082a0f84538f1f4291fa6a33e47565d1f246cefeb42e6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='927bdba9-4d8f-4f30-8616-aaea825a8582', node_type='1', metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, hash='39bb78c1f438ee4dc287319dffbda8df27ffe7d4b20225d5fbf3007bb69c5533'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='05df5cf9-cbef-4b50-9ef6-c9446f2e6642', node_type='1', metadata={}, hash='0b290254d3451f302e2f99edf1a476495fa1191e06c7479d77fe1dd8c5baac33')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='a cultural expert interested', mimetype='text/plain', start_char_idx=21, end_char_idx=49, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5027878820093544), NodeWithScore(node=TextNode(id_='927bdba9-4d8f-4f30-8616-aaea825a8582', embedding=None, metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='24e36899-ca32-4944-b60f-175d9b9aba26', node_type='4', metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, hash='e8f6a6656fcf54071fa082a0f84538f1f4291fa6a33e47565d1f246cefeb42e6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='10749000-c49f-4368-a98c-9e2dfc0d6de3', node_type='1', metadata={}, hash='9edbe4f3daf4b448b356785051e8d4120f0fbc938ac1ceaac1b13f59e37ac248')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or', mimetype='text/plain', start_char_idx=0, end_char_idx=20, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4948245579236253)], metadata={'10749000-c49f-4368-a98c-9e2dfc0d6de3': {'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, '927bdba9-4d8f-4f30-8616-aaea825a8582': {'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()  # This is needed to run the query engine\n",
    "llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    response_mode=\"tree_summarize\",\n",
    ")\n",
    "response1 = query_engine.query(\n",
    "    \"Respond using a persona that describes author and travel experiences?\"\n",
    ")\n",
    "response1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and observability\n",
    "\n",
    "LlamaIndex provides built-in evaluation tools to assess response quality. \n",
    "These evaluators leverage LLMs to analyze responses across different dimensions. Letâ€™s look at the three main evaluators available:\n",
    "\n",
    "FaithfulnessEvaluator: Evaluates the faithfulness of the answer by checking if the answer is supported by the context.\n",
    "AnswerRelevancyEvaluator: Evaluate the relevance of the answer by checking if the answer is relevant to the question.\n",
    "CorrectnessEvaluator: Evaluate the correctness of the answer by checking if the answer is correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
    "from llama_index.core.evaluation import AnswerRelevancyEvaluator\n",
    "from llama_index.core.evaluation import CorrectnessEvaluator\n",
    "\n",
    "# query index\n",
    "evaluator = FaithfulnessEvaluator(llm=llm)\n",
    "evaluator1 = AnswerRelevancyEvaluator(llm=llm)\n",
    "evaluator2 = CorrectnessEvaluator(llm=llm)\n",
    "response = query_engine.query(\n",
    "    \"What battles took place in New York City in the American Revolution?\"\n",
    ")\n",
    "eval_result = evaluator.evaluate_response(response=response)\n",
    "eval_result.passing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result1 = evaluator.evaluate_response(response=response1)\n",
    "eval_result1.passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one of these LLM based evaluators does not give enough context, we can check the response using the Arize Phoenix tool, after creating an account at LlamaTrace and generating an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_index\n",
    "import os\n",
    "\n",
    "PHOENIX_API_KEY = \"<PHOENIX_API_KEY>\"\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "llama_index.core.set_global_handler(\n",
    "    \"arize_phoenix\", endpoint=\"https://llamatrace.com/v1/traces\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can query the index and see the response in the Arize Phoenix tool.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='The provided information does not mention anyone interested in AI and technology. It only refers to an anthropologist or a cultural expert.', source_nodes=[NodeWithScore(node=TextNode(id_='927bdba9-4d8f-4f30-8616-aaea825a8582', embedding=None, metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='24e36899-ca32-4944-b60f-175d9b9aba26', node_type='4', metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, hash='e8f6a6656fcf54071fa082a0f84538f1f4291fa6a33e47565d1f246cefeb42e6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='10749000-c49f-4368-a98c-9e2dfc0d6de3', node_type='1', metadata={}, hash='9edbe4f3daf4b448b356785051e8d4120f0fbc938ac1ceaac1b13f59e37ac248')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or', mimetype='text/plain', start_char_idx=0, end_char_idx=20, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4140158267264093), NodeWithScore(node=TextNode(id_='10749000-c49f-4368-a98c-9e2dfc0d6de3', embedding=None, metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='24e36899-ca32-4944-b60f-175d9b9aba26', node_type='4', metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, hash='e8f6a6656fcf54071fa082a0f84538f1f4291fa6a33e47565d1f246cefeb42e6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='927bdba9-4d8f-4f30-8616-aaea825a8582', node_type='1', metadata={'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, hash='39bb78c1f438ee4dc287319dffbda8df27ffe7d4b20225d5fbf3007bb69c5533'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='05df5cf9-cbef-4b50-9ef6-c9446f2e6642', node_type='1', metadata={}, hash='0b290254d3451f302e2f99edf1a476495fa1191e06c7479d77fe1dd8c5baac33')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='a cultural expert interested', mimetype='text/plain', start_char_idx=21, end_char_idx=49, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.41092754312064916)], metadata={'927bdba9-4d8f-4f30-8616-aaea825a8582': {'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}, '10749000-c49f-4368-a98c-9e2dfc0d6de3': {'file_path': '/Users/loicsteve/Desktop/LlamaIndexAgents/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-04-16', 'last_modified_date': '2025-04-16'}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is the name of the someone that is interested in AI and techhnology?\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndexAgent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
