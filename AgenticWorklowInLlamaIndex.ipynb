{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index llama-index-vector-stores-chroma llama-index-utils-workflow llama-index-llms-huggingface-api pyvis -U -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Workflow creation\n",
    "\n",
    "We can start by creating a simple workflow. We use the StartEvent and StopEvent classes to define the start and stop of the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, world!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.workflow import StartEvent, StopEvent, Workflow, step\n",
    "\n",
    "\n",
    "class MyWorkflow(Workflow):\n",
    "    @step\n",
    "    async def my_step(self, ev: StartEvent) -> StopEvent:\n",
    "        # do something here\n",
    "        return StopEvent(result=\"Hello, world!\")\n",
    "\n",
    "\n",
    "w = MyWorkflow(timeout=10, verbose=False)\n",
    "#As you can see, we will now run the workflow by calling w.run()\n",
    "result = await w.run()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting multiple steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Finished processing: Step 1 complete'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.workflow import Event\n",
    "\n",
    "class ProcessingEvent(Event):\n",
    "    intermediate_result: str\n",
    "\n",
    "class MultiStepWorkflow(Workflow):\n",
    "    @step\n",
    "    async def step_one(self, ev: StartEvent) -> ProcessingEvent:\n",
    "        # Process initial data\n",
    "        return ProcessingEvent(intermediate_result=\"Step 1 complete\")\n",
    "    # @step\n",
    "    # async def step_two(self, ev: ProcessingEvent) -> ProcessingEvent:\n",
    "    #     #process first step\n",
    "    #     return ProcessingEvent(intermediate_result=\"step 2 complete\")\n",
    "    @step\n",
    "    async def step_two(self, ev: ProcessingEvent) -> StopEvent:\n",
    "        # Use the intermediate result\n",
    "        final_result = f\"Finished processing: {ev.intermediate_result}\"\n",
    "        return StopEvent(result=final_result)\n",
    "\n",
    "w = MultiStepWorkflow(timeout=10, verbose=False)\n",
    "result = await w.run()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loops and Branches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use type hinting to create branches and loops. Note that we can use the | operator to specify that the step can return multiple types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good thing happened\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished processing: First step complete.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.workflow import Event\n",
    "import random\n",
    "\n",
    "\n",
    "class ProcessingEvent(Event):\n",
    "    intermediate_result: str\n",
    "\n",
    "\n",
    "class LoopEvent(Event):\n",
    "    loop_output: str\n",
    "\n",
    "\n",
    "class MultiStepWorkflow(Workflow):\n",
    "    @step\n",
    "    async def step_one(self, ev: StartEvent | LoopEvent) -> ProcessingEvent | LoopEvent:\n",
    "        if random.randint(0, 1) == 0:\n",
    "            print(\"Bad thing happened\")\n",
    "            return LoopEvent(loop_output=\"Back to step one.\")\n",
    "        else:\n",
    "            print(\"Good thing happened\")\n",
    "            return ProcessingEvent(intermediate_result=\"First step complete.\")\n",
    "\n",
    "    @step\n",
    "    async def step_two(self, ev: ProcessingEvent) -> StopEvent:\n",
    "        # Use the intermediate result\n",
    "        final_result = f\"Finished processing: {ev.intermediate_result}\"\n",
    "        return StopEvent(result=final_result)\n",
    "\n",
    "\n",
    "w = MultiStepWorkflow(verbose=False)\n",
    "result = await w.run()\n",
    "result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndexAgent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
